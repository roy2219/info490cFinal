{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "# Modules from scikit-learn\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv(\"Dataset/Fake.csv\")\n",
    "true = pd.read_csv(\"Dataset/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looping through and adding every text to a string for True\n",
    "trueCorpus = []\n",
    "fakeCorpus = []\n",
    "for i in true['text']:\n",
    "    trueCorpus.append(i) \n",
    "\n",
    "for i in fake['text']:\n",
    "    fakeCorpus.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizing texts with NLTK\n",
    "tokenized_True = [word_tokenize(i) for i in trueCorpus]\n",
    "tokenized_True = [word_tokenize(i) for i in fakeCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trueCorpus Length: \"+ str(len(tokenized_True)))\n",
    "print(\"fakeCorpus Length: \"+ str(len(tokenized_Fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing Stopwords from the Corpus\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filteredTrue = []\n",
    "filteredFake = []\n",
    "\n",
    "for wordList in tokenized_True:\n",
    "    for word in wordList:\n",
    "        if word not in stop_words:\n",
    "            filteredTrue.append(word)\n",
    "\n",
    "for word in tokenized_True:\n",
    "    for word in wordList:\n",
    "        if word not in stop_words:\n",
    "            filteredFake.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6935100\n"
     ]
    }
   ],
   "source": [
    "print(len(filteredTrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Donald', 'Trump', 'wish', 'Americans', 'Happy', 'New', 'Year', 'leave', '.', 'Instead', ',', 'give', 'shout', 'enemies', ',', 'haters', 'dishonest', 'fake', 'news', 'media', '.', 'The', 'former', 'reality', 'show', 'star', 'one', 'job', '.', 'As', 'Country', 'rapidly', 'grows', 'stronger', 'smarter', ',', 'I', 'want', 'wish', 'friends', ',', 'supporters', ',', 'enemies', ',', 'haters', ',', 'even', 'dishonest', 'Fake', 'News', 'Media', ',', 'Happy', 'Healthy', 'New', 'Year', ',', 'President', 'Angry', 'Pants', 'tweeted', '.', '2018', 'great', 'year', 'America', '!', 'As', 'Country', 'rapidly', 'grows', 'stronger', 'smarter', ',', 'I', 'want', 'wish', 'friends', ',', 'supporters', ',', 'enemies', ',', 'haters', ',', 'even', 'dishonest', 'Fake', 'News', 'Media', ',', 'Happy', 'Healthy', 'New', 'Year', '.', '2018', 'great', 'year', 'America', '!', 'Donald', 'J.', 'Trump', '(', '@', 'realDonaldTrump', ')', 'December', '31', ',', '2017Trump', 'tweet', 'went', 'welll', 'expect.What', 'kind', 'president', 'sends', 'New', 'Year', 'greeting', 'like', 'despicable', ',', 'petty', ',', 'infantile', 'gibberish', '?', 'Only', 'Trump', '!', 'His', 'lack', 'decency', 'even', 'allow', 'rise', 'gutter', 'long', 'enough', 'wish', 'American', 'citizens', 'happy', 'new', 'year', '!', 'Bishop', 'Talbert', 'Swan', '(', '@', 'TalbertSwan', ')', 'December', '31', ',', '2017no', 'one', 'likes', 'Calvin', '(', '@', 'calvinstowell', ')', 'December', '31', ',', '2017Your', 'impeachment', 'would', 'make', '2018', 'great', 'year', 'America', ',', 'I', 'also', 'accept', 'regaining', 'control', 'Congress', '.', 'Miranda', 'Yaver', '(', '@', 'mirandayaver', ')', 'December', '31', ',', '2017Do', 'hear', 'talk', '?', 'When', 'include', 'many', 'people', 'hate', 'wonder', '?', 'Why', 'hate', '?', 'Alan', 'Sandoval', '(', '@', 'AlanSandoval13', ')', 'December', '31', ',', '2017Who', 'uses', 'word', 'Haters', 'New', 'Years', 'wish', '?', '?', 'Marlene', '(', '@', 'marlene399', ')', 'December', '31', ',', '2017You', 'say', 'happy', 'new', 'year', '?', 'Koren', 'pollitt', '(', '@', 'Korencarpenter', ')', 'December', '31', ',', '2017Here', 'Trump', 'New', 'Year', 'Eve', 'tweet', '2016.Happy', 'New', 'Year', ',', 'including', 'many', 'enemies', 'fought', 'lost', 'badly', 'know', '.', 'Love', '!', 'Donald', 'J.', 'Trump', '(', '@', 'realDonaldTrump', ')', 'December', '31', ',', '2016This', 'nothing', 'new', 'Trump', '.', 'He', 'years.Trump', 'directed', 'messages', 'enemies', 'haters', 'New', 'Year', ',', 'Easter', ',', 'Thanksgiving', ',', 'anniversary', '9/11', '.', 'pic.twitter.com/4FPAe2KypA', 'Daniel', 'Dale', '(', '@', 'ddale8', ')', 'December', '31', ',', '2017Trump', 'holiday', 'tweets', 'clearly', 'presidential.How', 'long', 'work', 'Hallmark', 'becoming', 'President', '?', 'Steven', 'Goodine', '(', '@', 'SGoodine', ')', 'December', '31', ',', '2017He', 'always', 'like', '.', '.', '.', 'difference', 'last', 'years', ',', 'filter', 'breaking', '.', 'Roy', 'Schulze', '(', '@', 'thbthttt', ')', 'December', '31', ',', '2017Who', ',', 'apart', 'teenager', 'uses', 'term', 'haters', '?', 'Wendy', '(', '@', 'WendyWhistles', ')', 'December', '31', ',', '2017he', 'fucking', '5', 'year', 'old', 'Who', 'Knows', '(', '@', 'rainyday80', ')', 'December', '31', ',', '2017So', ',', 'people', 'voted', 'hole', 'thinking', 'would', 'change', 'got', 'power', ',', 'wrong', '!', '70-year-old', 'men', 'change', 'year', 'older.Photo', 'Andrew', 'Burton/Getty', 'Images', '.', 'House', 'Intelligence', 'Committee', 'Chairman', 'Devin', 'Nunes', 'going', 'bad', 'day', '.', 'He', 'assumption', ',', 'like', 'many', 'us', ',', 'Christopher', 'Steele-dossier', 'prompted', 'Russia', 'investigation', 'lashing', 'Department', 'Justice', 'FBI', 'order', 'protect', 'Trump', '.', 'As', 'happens', ',', 'dossier', 'started', 'investigation', ',', 'according', 'documents', 'obtained', 'New', 'York', 'Times.Former', 'Trump', 'campaign', 'adviser', 'George', 'Papadopoulos', 'drunk', 'wine', 'bar', 'revealed', 'knowledge', 'Russian', 'opposition', 'research', 'Hillary', 'Clinton.On', 'top', ',', 'Papadopoulos', 'covfefe', 'boy', 'Trump', ',', 'administration', 'alleged', '.', 'He', 'much', 'larger', 'role', ',', 'none', 'damning', 'drunken', 'fool', 'wine', 'bar', '.', 'Coffee', 'boys', 'help', 'arrange', 'New', 'York', 'meeting', 'Trump', 'President', 'Abdel', 'Fattah', 'el-Sisi', 'Egypt', 'two', 'months', 'election', '.', 'It', 'known', 'former', 'aide', 'set', 'meetings', 'world', 'leaders', 'Trump', ',', 'team', 'Trump', 'ran', 'merely', 'coffee', 'boy.In', 'May', '2016', ',', 'Papadopoulos', 'revealed', 'Australian', 'diplomat', 'Alexander', 'Downer', 'Russian', 'officials', 'shopping', 'around', 'possible', 'dirt', 'then-Democratic', 'presidential', 'nominee', 'Hillary', 'Clinton', '.', 'Exactly', 'much', 'Mr.', 'Papadopoulos', 'said', 'night', 'Kensington', 'Wine', 'Rooms', 'Australian', ',', 'Alexander', 'Downer', ',', 'unclear', ',', 'report', 'states', '.', 'But', 'two', 'months', 'later', ',', 'leaked', 'Democratic', 'emails', 'began', 'appearing', 'online', ',', 'Australian', 'officials', 'passed', 'information', 'Mr.', 'Papadopoulos', 'American', 'counterparts', ',', 'according', 'four', 'current', 'former', 'American', 'foreign', 'officials', 'direct', 'knowledge', 'Australians', 'role', '.', 'Papadopoulos', 'pleaded', 'guilty', 'lying', 'F.B.I', '.', 'cooperating', 'witness', 'Special', 'Counsel', 'Robert', 'Mueller', 'team.This', 'presidency', '.', 'It', 'badly', 'scripted', 'reality', 'TV', 'show.Photo', 'Win', 'McNamee/Getty', 'Images', '.', 'On', 'Friday', ',', 'revealed', 'former', 'Milwaukee', 'Sheriff', 'David', 'Clarke', ',', 'considered', 'Homeland', 'Security', 'Secretary', 'Donald', 'Trump', 'administration', ',', 'email', 'scandal', 'own.In', 'January', ',', 'brief', 'run-in', 'plane', 'Clarke', 'fellow', 'passenger', 'Dan', 'Black', ',', 'later', 'detained', 'police', 'reason', 'whatsoever', ',', 'except', 'maybe', 'feelings', 'hurt', '.', 'Clarke', 'messaged', 'police', 'stop', 'Black', 'deplaned', ',', ',', 'search', 'warrant', 'executed', 'FBI', 'see', 'exchanges.Clarke', 'calling', 'fake', 'news', 'even', 'though', 'copies', 'search', 'warrant', 'Internet', '.', 'I', 'UNINTIMIDATED', 'lib', 'media', 'attempts', 'smear', 'discredit', 'FAKE', 'NEWS', 'reports', 'designed', 'silence', ',', 'former', 'sheriff', 'tweeted', '.', 'I', 'continue', 'poke', 'eye', 'sharp', 'stick', 'bitch', 'slap', 'scum', 'bags', 'til', 'get', '.', 'I', 'attacked', 'better', 'people', '#', 'MAGA', 'I', 'UNINTIMIDATED', 'lib', 'media', 'attempts', 'smear', 'discredit', 'FAKE', 'NEWS', 'reports', 'designed', 'silence', '.', 'I', 'continue', 'poke', 'eye', 'sharp', 'stick', 'bitch', 'slap', 'scum', 'bags', 'til', 'get', '.', 'I', 'attacked', 'better', 'people', '#', 'MAGA', 'pic.twitter.com/XtZW5PdU2b', 'David', 'A.', 'Clarke', ',', 'Jr.', '(', '@', 'SheriffClarke', ')', 'December', '30', ',', '2017He', 'stop', 'there.BREAKING', 'NEWS', '!', 'When', 'LYING', 'LIB', 'MEDIA', 'makes', 'FAKE', 'NEWS', 'smear', ',', 'ANTIDOTE', 'go', 'right', '.', 'Punch', 'nose', '&', 'MAKE', 'THEM', 'TASTE', 'THEIR', 'OWN', 'BLOOD', '.', 'Nothing', 'gets', 'bully', 'like', 'LYING', 'LIB', 'MEDIA', 'S', 'attention', 'better', 'give', 'taste', 'blood', '#', 'neverbackdown', 'pic.twitter.com/T2NY2psHCR', 'David', 'A.', 'Clarke', ',', 'Jr.', '(', '@', 'SheriffClarke', ')', 'December', '30', ',', '2017The', 'internet', 'called', 'out.This', 'local', 'newspaper', 'search', 'warrant', 'fake', ',', 'chose', 'file', 'charges', 'time', 'mean', '!', 'Especially', 'continue', 'lie', '.', 'Months', 'decision', 'charge', 'Clarke', ',', 'email', 'search', 'warrant', 'filed', 'https', ':', '//t.co/zcbyc4Wp5b', 'KeithLeBlanc', '(', '@', 'KeithLeBlanc63', ')', 'December', '30', ',', '2017I', 'hope', 'rest', 'Village', 'People', 'implicated', '.', 'Kirk', 'Ketchum', '(', '@', 'kirkketchum', ')', 'December', '30', ',', '2017Slaw', ',', 'baked', 'potatoes', ',', 'French', 'fries', '?', 'pic.twitter.com/fWfXsZupxy', 'ALT-', 'Immigration', '(', '@', 'ALT_uscis', ')', 'December', '30', ',', '2017pic.twitter.com/ymsOBLjfxU', 'Pendulum', 'Swinger', '(', '@', 'PendulumSwngr', ')', 'December', '30', ',', '2017you', 'called', 'police', 'friends', 'stand', 'someone', 'made', 'fun', 'hat', 'Chris', 'Jackson', '(', '@', 'ChrisCJackson', ')', 'December', '30', ',', '2017Is', ',', 'masterful', 'pshop', 'hat', ',', 'I', 'seem', 'never', 'tire', '.', 'I', 'think', 'steely', 'resolve', 'one', 'visible', 'eye', 'pic.twitter.com/dWr5k8ZEZV', 'Chris', 'Mohney', '(', '@', 'chrismohney', ')', 'December', '30', ',', '2017Are', 'indicating', 'fingers', 'many', 'people', 'died', 'jail', '?', 'I', 'think', 'fingers', 'short', ',', 'dipshit', 'Ike', 'Barinholtz', '(', '@', 'ikebarinholtz', ')', 'December', '30', ',', '2017ROFL', '.', 'Internet', 'tough', 'guy', 'fake', 'flair', '.', 'pic.twitter.com/ulCFddhkdy', 'KellMeCrazy', '(', '@', 'Kel_MoonFace', ')', 'December', '30', ',', '2017You', 'edgy', ',', 'buddy', '.', 'Mrs.', 'SMH', '(', '@']\n"
     ]
    }
   ],
   "source": [
    "print(filteredTrue[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'she', 'those', 'he', 'shouldn', 'her', 've', 'its', 'during', 'themselves', 'hers', 'then', \"you're\", 'i', 'couldn', 'who', 'do', 'own', \"should've\", \"you'll\", \"hasn't\", \"you'd\", 'not', 'this', 'other', 'into', 'had', 'until', 'any', 'm', 'needn', 'through', 'didn', 'them', 'his', 'by', 'against', \"wasn't\", \"didn't\", 'before', 're', 'our', 'all', 'nor', 'both', 'having', 'mustn', 'why', 'with', 'isn', 'to', 'below', \"doesn't\", 'such', 'it', 'wouldn', 'my', 'we', 'or', 'most', 'weren', 'some', 'aren', 'out', 'don', 'your', 'be', 'being', \"don't\", 'after', 'than', 'they', 'while', 'no', 'very', 'herself', 'over', 'as', 'mightn', 'yours', 'is', \"won't\", 'did', 'how', 'doesn', 'me', 'if', 'a', 'further', 'wasn', 'at', 'd', 'o', \"mightn't\", 'above', 'each', 'up', 'again', \"couldn't\", 'just', 'few', 'where', 'too', 'these', 'were', 'when', \"aren't\", 'the', 'but', 'was', 'for', 'yourselves', 'of', 'ours', 'between', 'so', 'more', 'been', 'under', \"wouldn't\", 'll', 'whom', \"you've\", \"isn't\", 'there', 'ma', 'theirs', 'because', 'ain', 'have', 'on', 'once', 't', 'same', 'doing', 'here', 'from', 'am', 'hasn', \"that'll\", 's', \"weren't\", 'should', \"mustn't\", 'has', 'that', 'does', 'y', 'haven', 'now', \"it's\", 'you', 'myself', \"shan't\", 'what', \"hadn't\", 'only', 'yourself', 'in', 'and', 'down', 'hadn', 'can', 'which', 'an', 'off', 'their', \"haven't\", 'will', 'shan', \"she's\", 'him', 'about', \"needn't\", 'himself', \"shouldn't\", 'itself', 'ourselves', 'won', 'are'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing Punctuation \n",
    "\n",
    "tempTrue  = ' '.join([str(elem) for elem in filteredTrue])\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "filteredTrue = tokenizer.tokenize(tempTrue)\n",
    "\n",
    "\n",
    "tempFalse  = ' '.join([str(elem) for elem in filteredFake])\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "filteredFake = tokenizer.tokenize(tempFalse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filteredFake)\n",
    "len(filteredTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
